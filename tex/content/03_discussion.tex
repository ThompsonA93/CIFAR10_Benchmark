\chapter{Discussion}
The computation on the CIFAR10 dataset has produced various results, some of which were questionable due to overfitting issues. 
Many results show that a neural network is not necessarily optimal, even when utilizing hyperparameter evaluation on a given data structure. 
Not only is the evaluation extremely costly in terms of time and power, but the resulting models may even perform less efficiently than a single, well-specified model. 

Over the many generations trained during this experimentation, the standard model did satisfactorily even compared to many optimal hyper models.
For hyper models, Hyperband was the most consistent algorithm, with results often surpassing the standard model.
On average, random search and bayesian optimization did worse than the standard model.

With respect to parametrization, most models do not significantly improve after 4 to 8 epochs. 
Hyperparameter evaluation further suggests, that reducing the number of layers decreases overall scores, rather than improving them.
Different parametrization, such as dropout and learning rate, can slightly improve accuracy.